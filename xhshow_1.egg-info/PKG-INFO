Metadata-Version: 2.4
Name: xhshow-1
Version: 0.1.0
Summary: Add your description here
Requires-Python: >=3.12
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: aiofiles~=24.1.0
Requires-Dist: beautifulsoup4~=4.13.3
Requires-Dist: demjson3>=3.0.6
Requires-Dist: dotenv>=0.9.9
Requires-Dist: loguru~=0.7.2
Requires-Dist: lxml~=5.3.0
Requires-Dist: openai>=1.68.2
Requires-Dist: openpyxl~=3.1.5
Requires-Dist: pandas~=2.2.3
Requires-Dist: pillow~=11.1.0
Requires-Dist: pycryptodome~=3.21.0
Requires-Dist: requests~=2.32.3
Requires-Dist: typeguard~=4.4.1
Dynamic: license-file
Dynamic: requires-python

# 景点分析工具

这是一个用于分析小红书景点相关笔记的工具，支持单个景点分析和批量处理多个景点。

## 功能特点

- **缓存和增量更新**
  - 利用已分析好的Excel文件作为缓存
  - 根据UID判断是否已分析，只处理新数据
  - 合并新旧结果，保持数据完整性

- **发布时间检测**
  - 自动检测笔记的发布时间
  - 如果连续2个帖子在2024年及以前，则停止继续分析
  - 将剩余帖子标记为"unnecessary"

- **流程自动化**
  - 自动化整个处理流程：搜索 → 相关性分析 → 详情获取
  - 支持命令行参数配置
  - 支持批量处理多个景点

- **日志和错误处理**
  - 详细的日志记录
  - 完善的错误处理机制
  - 批处理过程中的自动重试和恢复

## 安装依赖

```bash
uv pip install -r requirements.txt
```

## 使用方法

### 1. 分析单个景点

```bash
python -m learn.analyze_attraction_cmd --keyword "西湖" --spot_id "1001" --log_level INFO
```

参数说明：
- `--keyword`: 景点名称（必填）
- `--spot_id`: 景点ID（必填）
- `--cookie`: 小红书cookie（可选）
- `--log_level`: 日志级别，可选值：DEBUG, INFO, WARNING, ERROR（默认：INFO）

### 2. 批量分析多个景点

首先准备一个包含景点信息的Excel文件（例如`attractions.xlsx`），格式如下：

| 景点名称 | 景点ID |
|---------|-------|
| 西湖 | 1001 |
| 故宫 | 1002 |
| ... | ... |

然后运行批量处理命令：

```bash
python -m learn.batch_analyze_attractions --input_file "attractions.xlsx" --cookie "your_cookie" --log_level INFO
```

参数说明：
- `--input_file`: 包含景点信息的Excel文件路径（必填）
- `--cookie`: 小红书cookie（可选）
- `--log_level`: 日志级别（默认：INFO）

## 文件存储结构

- 搜索结果：`processed/{景点ID}.xlsx`
- 分析结果：`processed/{景点ID}_analyzed.xlsx`
- 相关笔记：`processed/{景点ID}_relevant.xlsx`
- 详情结果：`processed/{景点ID}_details.xlsx`
- 批处理结果：`results/batch_results_{日期}.xlsx`

## 实现细节

### 避免重复分析
- 每次分析前检查是否已有分析结果
- 根据UID过滤出未分析的数据
- 合并旧的分析结果和新的分析结果

### 发布时间检测逻辑
- 先按发布时间排序（如果有）
- 维护一个连续旧帖子计数器
- 如果遇到2024年前的帖子，计数器+1
- 如果计数器达到2，则停止处理并标记剩余帖子

### 异常处理
- 每个主要功能都有完善的异常处理
- 批处理过程中单个景点失败不影响整体处理
- 定期保存中间结果，避免数据丢失

## 日志系统

- 日志文件保存在`logs`目录下
- 支持不同级别的日志记录（DEBUG, INFO, WARNING, ERROR）
- 日志同时输出到文件和控制台
- 日志文件自动轮转和压缩

## 注意事项

1. 使用前请确保已安装所有依赖
2. 建议使用Python 3.8或更高版本
3. 需要提供有效的小红书cookie才能正常使用
4. 批量处理时建议先测试单个景点
5. 定期检查日志文件大小，必要时清理

## 常见问题

1. **Q: 为什么某些笔记被标记为"unnecessary"?**
   A: 这是因为检测到连续2个2024年及以前的帖子，系统自动停止并标记剩余帖子。

2. **Q: 如何查看分析进度？**
   A: 可以通过查看日志文件或控制台输出来了解分析进度。

3. **Q: 分析结果保存在哪里？**
   A: 所有结果文件都保存在`processed`目录下，批处理结果保存在`results`目录下。

## 贡献指南

欢迎提交Issue和Pull Request来帮助改进这个项目。在提交代码前，请确保：

1. 代码符合PEP 8规范
2. 添加了必要的注释和文档
3. 更新了相关的测试用例
4. 更新了README文件（如果需要）
